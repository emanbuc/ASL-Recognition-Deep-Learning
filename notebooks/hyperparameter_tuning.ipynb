{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train model - No HyperDrive"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install azureml-sdk[notebooks]\n",
        "!pip install torch\n",
        "!pip install torchvision\n",
        "!pip install tensorflow"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (1.6.0)\n",
            "Requirement already satisfied: dotnetcore2<3.0.0,>=2.1.14 in c:\\python38\\lib\\site-packages (from azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (2.1.20)\n",
            "Requirement already satisfied: azureml-dataprep-native<27.0.0,>=26.0.0 in c:\\python38\\lib\\site-packages (from azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (26.0.0)\n",
            "Requirement already satisfied: azureml-dataprep-rslex<1.5.0a,>=1.4.0dev0 in c:\\python38\\lib\\site-packages (from azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (1.4.0)\n",
            "Requirement already satisfied: azure-core<2.0.0,>=1.0.0 in c:\\python38\\lib\\site-packages (from azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (1.9.0)\n",
            "Requirement already satisfied: msal-extensions~=0.2.2 in c:\\python38\\lib\\site-packages (from azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (0.2.2)\n",
            "Requirement already satisfied: six>=1.6 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (1.15.0)\n",
            "Requirement already satisfied: msal<2.0.0,>=1.3.0 in c:\\python38\\lib\\site-packages (from azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (1.8.0)\n",
            "Requirement already satisfied: azureml-pipeline-steps~=1.19.0 in c:\\python38\\lib\\site-packages (from azureml-pipeline~=1.19.0->azureml-sdk[notebooks]) (1.19.0)\n",
            "Requirement already satisfied: azureml-train-core~=1.19.0 in c:\\python38\\lib\\site-packages (from azureml-pipeline-steps~=1.19.0->azureml-pipeline~=1.19.0->azureml-sdk[notebooks]) (1.19.0)\n",
            "Requirement already satisfied: azureml-telemetry~=1.19.0 in c:\\python38\\lib\\site-packages (from azureml-train-automl-client~=1.19.0->azureml-sdk[notebooks]) (1.19.0)\n",
            "Requirement already satisfied: azureml-automl-core~=1.19.0 in c:\\python38\\lib\\site-packages (from azureml-train-automl-client~=1.19.0->azureml-sdk[notebooks]) (1.19.0)\n",
            "Requirement already satisfied: applicationinsights in c:\\python38\\lib\\site-packages (from azureml-telemetry~=1.19.0->azureml-train-automl-client~=1.19.0->azureml-sdk[notebooks]) (0.11.9)\n",
            "Requirement already satisfied: azureml-train-restclients-hyperdrive~=1.19.0 in c:\\python38\\lib\\site-packages (from azureml-train-core~=1.19.0->azureml-pipeline-steps~=1.19.0->azureml-pipeline~=1.19.0->azureml-sdk[notebooks]) (1.19.0)\n",
            "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\python38\\lib\\site-packages (from azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (7.6.3)\n",
            "Requirement already satisfied: cffi>=1.12 in c:\\python38\\lib\\site-packages (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.19.0->azureml-sdk[notebooks]) (1.14.4)\n",
            "Requirement already satisfied: pycparser in c:\\python38\\lib\\site-packages (from cffi>=1.12->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core~=1.19.0->azureml-sdk[notebooks]) (2.20)\n",
            "Requirement already satisfied: distro>=1.2.0 in c:\\python38\\lib\\site-packages (from dotnetcore2<3.0.0,>=2.1.14->azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (1.5.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (5.0.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\python38\\lib\\site-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (3.5.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in c:\\python38\\lib\\site-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (5.1.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\python38\\lib\\site-packages (from ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (1.0.0)\n",
            "Requirement already satisfied: tornado>=4.2 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipykernel->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (6.1)\n",
            "Requirement already satisfied: jupyter-client in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipykernel->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (6.1.11)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.7.5)\n",
            "Requirement already satisfied: jedi>=0.10 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.18.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in c:\\python38\\lib\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (41.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (3.0.10)\n",
            "Requirement already satisfied: pygments in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (2.7.3)\n",
            "Requirement already satisfied: decorator in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (4.4.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.4.4)\n",
            "Requirement already satisfied: backcall in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.2.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from jedi>=0.10->ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.8.1)\n",
            "Requirement already satisfied: portalocker~=1.6 in c:\\python38\\lib\\site-packages (from msal-extensions~=0.2.2->azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (1.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\python38\\lib\\site-packages (from msrest>=0.5.1->azureml-core~=1.19.0->azureml-sdk[notebooks]) (1.3.0)\n",
            "Requirement already satisfied: isodate>=0.6.0 in c:\\python38\\lib\\site-packages (from msrest>=0.5.1->azureml-core~=1.19.0->azureml-sdk[notebooks]) (0.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from msrest>=0.5.1->azureml-core~=1.19.0->azureml-sdk[notebooks]) (2020.12.5)\n",
            "Requirement already satisfied: jinja2>=2.4 in c:\\python38\\lib\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (2.11.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in c:\\python38\\lib\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\python38\\lib\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.8.4)\n",
            "Requirement already satisfied: jupyter-core in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (4.7.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\python38\\lib\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (1.4.3)\n",
            "Requirement already satisfied: testpath in c:\\python38\\lib\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in c:\\python38\\lib\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.6.0)\n",
            "Requirement already satisfied: bleach in c:\\python38\\lib\\site-packages (from nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\python38\\lib\\site-packages (from jinja2>=2.4->nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (1.1.1)\n",
            "Requirement already satisfied: ipython-genutils in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\python38\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (3.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in c:\\python38\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (20.3.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\python38\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (0.17.3)\n",
            "Requirement already satisfied: ansiwrap in c:\\python38\\lib\\site-packages (from papermill<2->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.8.4)\n",
            "Requirement already satisfied: future in c:\\python38\\lib\\site-packages (from papermill<2->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.18.2)\n",
            "Requirement already satisfied: pyyaml in c:\\python38\\lib\\site-packages (from papermill<2->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in c:\\python38\\lib\\site-packages (from papermill<2->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (4.56.0)\n",
            "Requirement already satisfied: click in c:\\python38\\lib\\site-packages (from papermill<2->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (7.1.2)\n",
            "Requirement already satisfied: tenacity in c:\\python38\\lib\\site-packages (from papermill<2->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (6.3.1)\n",
            "Requirement already satisfied: pywin32!=226 in c:\\python38\\lib\\site-packages (from portalocker~=1.6->msal-extensions~=0.2.2->azure-identity<1.5.0,>=1.2.0->azureml-dataprep<2.7.0a,>=2.6.0a->azureml-dataset-runtime[fuse]~=1.19.0->azureml-sdk[notebooks]) (227)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.2.5)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python38\\lib\\site-packages (from requests>=2.19.1->azureml-core~=1.19.0->azureml-sdk[notebooks]) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\python38\\lib\\site-packages (from requests>=2.19.1->azureml-core~=1.19.0->azureml-sdk[notebooks]) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core~=1.19.0->azureml-sdk[notebooks]) (3.1.0)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2 in c:\\python38\\lib\\site-packages (from ruamel.yaml>=0.15.35->azureml-core~=1.19.0->azureml-sdk[notebooks]) (0.2.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in c:\\python38\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (6.2.0)\n",
            "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (1.5.0)\n",
            "Requirement already satisfied: prometheus-client in c:\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (0.9.0)\n",
            "Requirement already satisfied: pyzmq>=17 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (20.0.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in c:\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (0.9.2)\n",
            "Requirement already satisfied: argon2-cffi in c:\\python38\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (20.1.0)\n",
            "Requirement already satisfied: pywinpty>=0.5 in c:\\python38\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->azureml-widgets~=1.19.0->azureml-sdk[notebooks]) (0.5.7)\n",
            "Requirement already satisfied: textwrap3>=0.9.2 in c:\\python38\\lib\\site-packages (from ansiwrap->papermill<2->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.9.2)\n",
            "Requirement already satisfied: backports.weakref in c:\\python38\\lib\\site-packages (from backports.tempfile->azureml-core~=1.19.0->azureml-sdk[notebooks]) (1.0.post1)\n",
            "Requirement already satisfied: webencodings in c:\\python38\\lib\\site-packages (from bleach->nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (0.5.1)\n",
            "Requirement already satisfied: packaging in c:\\python38\\lib\\site-packages (from bleach->nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (20.8)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in c:\\python38\\lib\\site-packages (from docker->azureml-core~=1.19.0->azureml-sdk[notebooks]) (0.57.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.1 in c:\\python38\\lib\\site-packages (from ndg-httpsclient->azureml-core~=1.19.0->azureml-sdk[notebooks]) (0.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\python38\\lib\\site-packages (from packaging->bleach->nbconvert<6->azureml-contrib-notebook~=1.19.0->azureml-sdk[notebooks]) (2.4.7)\n",
            "Requirement already satisfied: jeepney>=0.6 in c:\\python38\\lib\\site-packages (from SecretStorage->azureml-core~=1.19.0->azureml-sdk[notebooks]) (0.6.0)\n",
            "Collecting torch\n",
            "  Downloading torch-1.7.1-cp38-cp38-win_amd64.whl (184.0 MB)\n",
            "Requirement already satisfied: typing-extensions in c:\\python38\\lib\\site-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in c:\\python38\\lib\\site-packages (from torch) (1.19.3)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.7.1\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.4.1-cp38-cp38-win_amd64.whl (370.7 MB)\n",
            "Requirement already satisfied: six~=1.15.0 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in c:\\python38\\lib\\site-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in c:\\python38\\lib\\site-packages (from tensorflow) (1.19.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\emanuele.buchicchio\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: wheel~=0.35 in c:\\python38\\lib\\site-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\python38\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
            "Collecting astunparse~=1.6.3\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting google-pasta~=0.2\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting opt-einsum~=3.3.0\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting tensorboard~=2.4\n",
            "  Downloading tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.25.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (41.2.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "  Downloading google_auth-1.24.0-py2.py3-none-any.whl (114 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Downloading cachetools-4.2.0-py3-none-any.whl (12 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.2-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python38\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.3-py3-none-any.whl (96 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\python38\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.26.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.7-py3-none-any.whl (34 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
            "Building wheels for collected packages: termcolor\n",
            "  Building wheel for termcolor (setup.py): started\n",
            "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=420d635dc83296705793642fbb0740e037ca202dfbaefe59e5ca91ae1243e4f1\n",
            "  Stored in directory: c:\\users\\emanuele.buchicchio\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "Successfully built termcolor\n",
            "Installing collected packages: rsa, pyasn1-modules, cachetools, google-auth, werkzeug, tensorboard-plugin-wit, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
            "Successfully installed absl-py-0.11.0 astunparse-1.6.3 cachetools-4.2.0 flatbuffers-1.12 gast-0.3.3 google-auth-1.24.0 google-auth-oauthlib-0.4.2 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.3.3 opt-einsum-3.3.0 pyasn1-modules-0.2.8 rsa-4.7 tensorboard-2.4.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 werkzeug-1.0.1\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "tags": [
          "outputPrepend"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1611268351340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Azure ML Imports\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from azureml.widgets import RunDetails"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1611268351555
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Workspace"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "experiment_name = 'ASL-DeepLearning-hyperameter'\n",
        "\n",
        "exp_with_hyper = Experiment(workspace=ws, name='Sign-Language-HyperDrive')\n",
        "exp_no_hyper = Experiment(workspace=ws, name='Sign-Language-NoHyperDrive')\n",
        "\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Falling back to use azure cli login credentials.\n",
            "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
            "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n",
            "Workspace name: quick-starts-ws-135706\n",
            "Azure region: southcentralus\n",
            "Subscription id: 48a74bb7-9950-4cc1-9caa-5d50f995cc55\n",
            "Resource group: aml-quickstarts-135706\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1611268352451
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a name for your CPU cluster\n",
        "cluster_name = \"gpu-cluster\"\n",
        "\n",
        "# Verify that cluster does not exist already\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_NC24',\n",
        "                                                           max_nodes=10)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1611268352978
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://www.kaggle.com/datamunge/sign-language-mnist\"\n",
        "\n",
        "found = False\n",
        "key = \"sign-language-mnist\"\n",
        "description_text = \"sign Language MNIST\"\n",
        "\n",
        "if key in ws.datasets.keys(): \n",
        "    found = True\n",
        "    ds = ws.datasets[key] \n",
        "\n",
        "if not found:\n",
        "    from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "    datastore_path = \"https://github.com/emanbuc/ASL-Recognition-Deep-Learning/raw/main/datasets/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv\"\n",
        "    ds = TabularDatasetFactory.from_delimited_files(path=datastore_path,header=True)       \n",
        "    #Register Dataset in Workspace\n",
        "    ds = ds.register(workspace=ws,\n",
        "                                   name=key,\n",
        "                                   description=description_text)\n",
        "\n",
        "\n",
        "df = ds.to_pandas_dataframe()\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              label        pixel1        pixel2        pixel3        pixel4  \\\n",
              "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
              "mean      12.318813    145.419377    148.500273    151.247714    153.546531   \n",
              "std        7.287552     41.358555     39.942152     39.056286     38.595247   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%        6.000000    121.000000    126.000000    130.000000    133.000000   \n",
              "50%       13.000000    150.000000    153.000000    156.000000    158.000000   \n",
              "75%       19.000000    174.000000    176.000000    178.000000    179.000000   \n",
              "max       24.000000    255.000000    255.000000    255.000000    255.000000   \n",
              "\n",
              "             pixel5        pixel6        pixel7        pixel8        pixel9  \\\n",
              "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
              "mean     156.210891    158.411255    160.472154    162.339683    163.954799   \n",
              "std       37.111165     36.125579     35.016392     33.661998     32.651607   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%      137.000000    140.000000    142.000000    144.000000    146.000000   \n",
              "50%      160.000000    162.000000    164.000000    165.000000    166.000000   \n",
              "75%      181.000000    182.000000    183.000000    184.000000    185.000000   \n",
              "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
              "\n",
              "       ...      pixel775      pixel776      pixel777      pixel778  \\\n",
              "count  ...  27455.000000  27455.000000  27455.000000  27455.000000   \n",
              "mean   ...    141.104863    147.495611    153.325806    159.125332   \n",
              "std    ...     63.751194     65.512894     64.427412     63.708507   \n",
              "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
              "25%    ...     92.000000     96.000000    103.000000    112.000000   \n",
              "50%    ...    144.000000    162.000000    172.000000    180.000000   \n",
              "75%    ...    196.000000    202.000000    205.000000    207.000000   \n",
              "max    ...    255.000000    255.000000    255.000000    255.000000   \n",
              "\n",
              "           pixel779      pixel780      pixel781      pixel782      pixel783  \\\n",
              "count  27455.000000  27455.000000  27455.000000  27455.000000  27455.000000   \n",
              "mean     161.969259    162.736696    162.906137    161.966454    161.137898   \n",
              "std       63.738316     63.444008     63.509210     63.298721     63.610415   \n",
              "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
              "25%      120.000000    125.000000    128.000000    128.000000    128.000000   \n",
              "50%      183.000000    184.000000    184.000000    182.000000    182.000000   \n",
              "75%      208.000000    207.000000    207.000000    206.000000    204.000000   \n",
              "max      255.000000    255.000000    255.000000    255.000000    255.000000   \n",
              "\n",
              "           pixel784  \n",
              "count  27455.000000  \n",
              "mean     159.824731  \n",
              "std       64.396846  \n",
              "min        0.000000  \n",
              "25%      125.500000  \n",
              "50%      182.000000  \n",
              "75%      204.000000  \n",
              "max      255.000000  \n",
              "\n",
              "[8 rows x 785 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>pixel9</th>\n      <th>...</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n      <th>pixel784</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>...</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n      <td>27455.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>12.318813</td>\n      <td>145.419377</td>\n      <td>148.500273</td>\n      <td>151.247714</td>\n      <td>153.546531</td>\n      <td>156.210891</td>\n      <td>158.411255</td>\n      <td>160.472154</td>\n      <td>162.339683</td>\n      <td>163.954799</td>\n      <td>...</td>\n      <td>141.104863</td>\n      <td>147.495611</td>\n      <td>153.325806</td>\n      <td>159.125332</td>\n      <td>161.969259</td>\n      <td>162.736696</td>\n      <td>162.906137</td>\n      <td>161.966454</td>\n      <td>161.137898</td>\n      <td>159.824731</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.287552</td>\n      <td>41.358555</td>\n      <td>39.942152</td>\n      <td>39.056286</td>\n      <td>38.595247</td>\n      <td>37.111165</td>\n      <td>36.125579</td>\n      <td>35.016392</td>\n      <td>33.661998</td>\n      <td>32.651607</td>\n      <td>...</td>\n      <td>63.751194</td>\n      <td>65.512894</td>\n      <td>64.427412</td>\n      <td>63.708507</td>\n      <td>63.738316</td>\n      <td>63.444008</td>\n      <td>63.509210</td>\n      <td>63.298721</td>\n      <td>63.610415</td>\n      <td>64.396846</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.000000</td>\n      <td>121.000000</td>\n      <td>126.000000</td>\n      <td>130.000000</td>\n      <td>133.000000</td>\n      <td>137.000000</td>\n      <td>140.000000</td>\n      <td>142.000000</td>\n      <td>144.000000</td>\n      <td>146.000000</td>\n      <td>...</td>\n      <td>92.000000</td>\n      <td>96.000000</td>\n      <td>103.000000</td>\n      <td>112.000000</td>\n      <td>120.000000</td>\n      <td>125.000000</td>\n      <td>128.000000</td>\n      <td>128.000000</td>\n      <td>128.000000</td>\n      <td>125.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>13.000000</td>\n      <td>150.000000</td>\n      <td>153.000000</td>\n      <td>156.000000</td>\n      <td>158.000000</td>\n      <td>160.000000</td>\n      <td>162.000000</td>\n      <td>164.000000</td>\n      <td>165.000000</td>\n      <td>166.000000</td>\n      <td>...</td>\n      <td>144.000000</td>\n      <td>162.000000</td>\n      <td>172.000000</td>\n      <td>180.000000</td>\n      <td>183.000000</td>\n      <td>184.000000</td>\n      <td>184.000000</td>\n      <td>182.000000</td>\n      <td>182.000000</td>\n      <td>182.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19.000000</td>\n      <td>174.000000</td>\n      <td>176.000000</td>\n      <td>178.000000</td>\n      <td>179.000000</td>\n      <td>181.000000</td>\n      <td>182.000000</td>\n      <td>183.000000</td>\n      <td>184.000000</td>\n      <td>185.000000</td>\n      <td>...</td>\n      <td>196.000000</td>\n      <td>202.000000</td>\n      <td>205.000000</td>\n      <td>207.000000</td>\n      <td>208.000000</td>\n      <td>207.000000</td>\n      <td>207.000000</td>\n      <td>206.000000</td>\n      <td>204.000000</td>\n      <td>204.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>24.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>...</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n      <td>255.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows Ã— 785 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1611268367891
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To map each label number to its corresponding letter\n",
        "letters = dict(enumerate(string.ascii_uppercase))\n",
        "letters"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'A',\n",
              " 1: 'B',\n",
              " 2: 'C',\n",
              " 3: 'D',\n",
              " 4: 'E',\n",
              " 5: 'F',\n",
              " 6: 'G',\n",
              " 7: 'H',\n",
              " 8: 'I',\n",
              " 9: 'J',\n",
              " 10: 'K',\n",
              " 11: 'L',\n",
              " 12: 'M',\n",
              " 13: 'N',\n",
              " 14: 'O',\n",
              " 15: 'P',\n",
              " 16: 'Q',\n",
              " 17: 'R',\n",
              " 18: 'S',\n",
              " 19: 'T',\n",
              " 20: 'U',\n",
              " 21: 'V',\n",
              " 22: 'W',\n",
              " 23: 'X',\n",
              " 24: 'Y',\n",
              " 25: 'Z'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1611268368176
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "targets = pd.get_dummies(df.pop('label')).values\n",
        "data = df.values\n",
        "targets.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1611268368423
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1611268368638
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import minmax_scale\n",
        "data = minmax_scale(data)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1611268368864
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (28,28, 1) # 28*28 = 784"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1611268368969
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.reshape(data,(-1, 28, 28,1))\n",
        "data.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1611268369366
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targets.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27455, 24)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1611268369564
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SPLITTING THE DATA INTO TRAIN SET AND TEST SET"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data, targets , test_size = 0.2, random_state=0)"
      ],
      "outputs": [],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1611268369848
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save data to file for remote cluster\n",
        "\n",
        "Salva i dati prepatati su file con pickle e esegue upload verso datastore del workspace in cloud."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import os\n",
        "if os.path.isfile('dataset/sign-language-mnist.pkl'):\n",
        "    print('File is present')\n",
        "else:\n",
        "    os.makedirs('dataset')\n",
        "    with open('dataset/sign-language-mnist.pkl','wb') as f:\n",
        "        pickle.dump((X_train,X_test,y_train,y_test),f)\n",
        "    \n",
        "    datastore=ws.get_default_datastore()\n",
        "    datastore.upload('./dataset', target_path='sign-language-mnist-data')\n",
        "\n",
        "print('Done')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File is present\n",
            "Done\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1611268370228
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remote Trainig Experiment\n",
        "\n",
        "Create an estimator object to run training experiment in remote compute cluster"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.estimator import Estimator\n",
        "script_params = {\n",
        "    '--data_folder': ws.get_default_datastore(),\n",
        "    '--hidden': 100\n",
        "}\n",
        "\n",
        "est = Estimator(source_directory='.',\n",
        "                script_params=script_params,\n",
        "                compute_target=cpu_cluster,\n",
        "                entry_script='train_keras.py',\n",
        "                pip_packages=['keras','tensorflow'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'Estimator' is deprecated. Please use 'ScriptRunConfig' from 'azureml.core.script_run_config' with your own defined environment or an Azure ML curated environment.\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1611268373877
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "run = exp_no_hyper.submit(est)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
            "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n",
            "Submitting /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-ds12/code/Users/odl_user_135645 directory for run. The size of the directory >= 25 MB, so it can take a few minutes.\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1611268379997
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remote Training with Hyper Drive"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperdrive Configuration\n",
        "\n",
        "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.hyperdrive.policy import BanditPolicy,MedianStoppingPolicy\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform, normal,choice"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611268380178
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Create the different params that you will be using during training\n",
        "param_sampling = RandomParameterSampling({\n",
        "         '--hidden': choice([50,100,200,300]),\n",
        "         '--batch_size': choice([64,128]), \n",
        "         '--epochs': choice([3,5,10]),\n",
        "         '--dropout': choice([0.5,0.8,1])})"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1611268380276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Create an early termination policy. This is not required if you are using Bayesian sampling.\n",
        "\n",
        "early_termination_policy = MedianStoppingPolicy()\n",
        "hd_config = HyperDriveConfig(estimator=est,\n",
        "  hyperparameter_sampling=param_sampling,\n",
        "  policy=early_termination_policy,\n",
        "  primary_metric_name='Accuracy',\n",
        "  primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "  max_total_runs=16,\n",
        "  max_concurrent_runs=4)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1611268380459
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "param_sampling = RandomParameterSampling({\n",
        "         '--hidden': choice([50,100,200,300]),\n",
        "         '--batch_size': choice([64,128]), \n",
        "         '--epochs': choice([5,10,50]),\n",
        "         '--dropout': choice([0.5,0.8,1])})"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "hyperdrive_run = exp_with_hyper.submit(hd_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
            "WARNING:root:If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n",
            "The same input parameter(s) are specified in estimator/run_config script params and HyperDrive parameter space. HyperDrive parameter space definition will override these duplicate entries. ['--hidden'] is the list of overridden parameter(s).\n"
          ]
        }
      ],
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1611270165893
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598544898497
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(hyperdrive_run).show()\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'â€¦",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7038264514a442289f139761139b73b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Sign-Language-HyperDrive/runs/HD_72710757-5b96-4e18-bb21-996afe488148?wsid=/subscriptions/610d6e37-4747-4a20-80eb-3aad70a55f43/resourcegroups/aml-quickstarts-135645/workspaces/quick-starts-ws-135645\", \"run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148\", \"run_properties\": {\"run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148\", \"created_utc\": \"2021-01-21T23:02:45.000732Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"c84ca848-9650-453b-8685-92d4515377c8\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"16\", \"max_total_jobs\": \"16\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"MEDIANSTOPPING\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0}}\", \"policy_config\": \"{\\\"name\\\": \\\"MEDIANSTOPPING\\\", \\\"properties\\\": {\\\"evaluation_interval\\\": 1, \\\"delay_evaluation\\\": 0}}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--hidden\\\": [\\\"choice\\\", [[50, 100, 200, 300]]], \\\"--batch_size\\\": [\\\"choice\\\", [[64, 128]]], \\\"--epochs\\\": [\\\"choice\\\", [[5, 10, 50]]], \\\"--dropout\\\": [\\\"choice\\\", [[0.5, 0.8, 1]]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"RANDOM\\\", \\\"parameter_space\\\": {\\\"--hidden\\\": [\\\"choice\\\", [[50, 100, 200, 300]]], \\\"--batch_size\\\": [\\\"choice\\\", [[64, 128]]], \\\"--epochs\\\": [\\\"choice\\\", [[5, 10, 50]]], \\\"--dropout\\\": [\\\"choice\\\", [[0.5, 0.8, 1]]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"Accuracy\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/610d6e37-4747-4a20-80eb-3aad70a55f43/resourceGroups/aml-quickstarts-135645/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-135645/experiments/Sign-Language-HyperDrive\\\", \\\"SubscriptionId\\\": \\\"610d6e37-4747-4a20-80eb-3aad70a55f43\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-135645\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-135645\\\", \\\"ExperimentName\\\": \\\"Sign-Language-HyperDrive\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_keras.py\\\", \\\"arguments\\\": [\\\"--data_folder\\\", \\\"$AZUREML_DATAREFERENCE_workspaceblobstore\\\"], \\\"target\\\": \\\"gpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"keras\\\", \\\"tensorflow\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"workspaceblobstore\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": null, \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"c84ca848-9650-453b-8685-92d4515377c8\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"594a09ca-25d0-4f28-a6a6-7015c8e687f5\\\", \\\"amlClientSessionId\\\": \\\"9696b090-4f42-4a40-a9be-8337af6782cc\\\", \\\"subscriptionId\\\": \\\"610d6e37-4747-4a20-80eb-3aad70a55f43\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"MedianStopping\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 16, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/610d6e37-4747-4a20-80eb-3aad70a55f43/resourceGroups/aml-quickstarts-135645/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-135645/experiments/Sign-Language-HyperDrive\\\", \\\"SubscriptionId\\\": \\\"610d6e37-4747-4a20-80eb-3aad70a55f43\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-135645\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-135645\\\", \\\"ExperimentName\\\": \\\"Sign-Language-HyperDrive\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train_keras.py\\\", \\\"arguments\\\": [\\\"--data_folder\\\", \\\"$AZUREML_DATAREFERENCE_workspaceblobstore\\\"], \\\"target\\\": \\\"gpu-cluster\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": null, \\\"nodeCount\\\": 1, \\\"environment\\\": {\\\"name\\\": null, \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"name\\\": \\\"project_environment\\\", \\\"dependencies\\\": [\\\"python=3.6.2\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"keras\\\", \\\"tensorflow\\\"]}], \\\"channels\\\": [\\\"anaconda\\\", \\\"conda-forge\\\"]}}, \\\"docker\\\": {\\\"enabled\\\": true, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20200821.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": false}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {\\\"workspaceblobstore\\\": {\\\"dataStoreName\\\": \\\"workspaceblobstore\\\", \\\"pathOnDataStore\\\": null, \\\"mode\\\": \\\"mount\\\", \\\"overwrite\\\": false, \\\"pathOnCompute\\\": null}}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": 1}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"c84ca848-9650-453b-8685-92d4515377c8\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"594a09ca-25d0-4f28-a6a6-7015c8e687f5\\\", \\\"amlClientSessionId\\\": \\\"9696b090-4f42-4a40-a9be-8337af6782cc\\\", \\\"subscriptionId\\\": \\\"610d6e37-4747-4a20-80eb-3aad70a55f43\\\", \\\"estimator\\\": \\\"Estimator\\\", \\\"samplingMethod\\\": \\\"RANDOM\\\", \\\"terminationPolicy\\\": \\\"MedianStopping\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 16, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"false\", \"all_jobs_generated\": \"false\", \"_aml_system_cancellation_requested\": \"false\", \"cancellation_requested\": \"false\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-01-21T23:02:45.800005\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-01-21T23:02:45.800005\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"6ba90d7da79d04e0276034eadf57dd526fac55610f6fd89105bb7f6e1ba621a9\\\"\", \"progress_metadata_digest\": \"\\\"6ba90d7da79d04e0276034eadf57dd526fac55610f6fd89105bb7f6e1ba621a9\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-01-21T23:02:45.800005\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-01-21T23:02:45.800005\\\"\", \"_aml_system_HD_72710757-5b96-4e18-bb21-996afe488148_0\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 1, \\\"--epochs\\\": 50, \\\"--hidden\\\": 50}\", \"HD_72710757-5b96-4e18-bb21-996afe488148_0\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 1, \\\"--epochs\\\": 50, \\\"--hidden\\\": 50}\", \"_aml_system_HD_72710757-5b96-4e18-bb21-996afe488148_1\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.8, \\\"--epochs\\\": 5, \\\"--hidden\\\": 100}\", \"HD_72710757-5b96-4e18-bb21-996afe488148_1\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.8, \\\"--epochs\\\": 5, \\\"--hidden\\\": 100}\", \"_aml_system_HD_72710757-5b96-4e18-bb21-996afe488148_2\": \"{\\\"--batch_size\\\": 128, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 5, \\\"--hidden\\\": 200}\", \"HD_72710757-5b96-4e18-bb21-996afe488148_2\": \"{\\\"--batch_size\\\": 128, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 5, \\\"--hidden\\\": 200}\", \"_aml_system_HD_72710757-5b96-4e18-bb21-996afe488148_3\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 50, \\\"--hidden\\\": 300}\", \"HD_72710757-5b96-4e18-bb21-996afe488148_3\": \"{\\\"--batch_size\\\": 64, \\\"--dropout\\\": 0.5, \\\"--epochs\\\": 50, \\\"--hidden\\\": 300}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148_preparation\", \"prepare_run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148_preparation\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg135645.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_72710757-5b96-4e18-bb21-996afe488148/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=O0TTrBLHPr6SuUfly57nCpocDBIAHRSN33kCk15p3sg%3D&st=2021-01-21T22%3A53%3A24Z&se=2021-01-22T07%3A03%3A24Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:00:39\", \"hyper_parameters\": {\"--hidden\": [\"choice\", [[50, 100, 200, 300]]], \"--batch_size\": [\"choice\", [[64, 128]]], \"--epochs\": [\"choice\", [[5, 10, 50]]], \"--dropout\": [\"choice\", [[0.5, 0.8, 1]]]}}, \"child_runs\": [{\"run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148_0\", \"run_number\": 5, \"metric\": null, \"status\": \"Queued\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"\", \"end_time\": \"\", \"created_time\": \"2021-01-21T23:03:19.017452Z\", \"created_time_dt\": \"2021-01-21T23:03:19.017452Z\", \"duration\": \"0:00:05\", \"hyperdrive_id\": \"72710757-5b96-4e18-bb21-996afe488148\", \"arguments\": null, \"param_--batch_size\": 64, \"param_--dropout\": 1, \"param_--epochs\": 50, \"param_--hidden\": 50}, {\"run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148_2\", \"run_number\": 7, \"metric\": null, \"status\": \"Queued\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"\", \"end_time\": \"\", \"created_time\": \"2021-01-21T23:03:19.525055Z\", \"created_time_dt\": \"2021-01-21T23:03:19.525055Z\", \"duration\": \"0:00:05\", \"hyperdrive_id\": \"72710757-5b96-4e18-bb21-996afe488148\", \"arguments\": null, \"param_--batch_size\": 128, \"param_--dropout\": 0.5, \"param_--epochs\": 5, \"param_--hidden\": 200}, {\"run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148_1\", \"run_number\": 4, \"metric\": null, \"status\": \"Queued\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"\", \"end_time\": \"\", \"created_time\": \"2021-01-21T23:03:18.880315Z\", \"created_time_dt\": \"2021-01-21T23:03:18.880315Z\", \"duration\": \"0:00:05\", \"hyperdrive_id\": \"72710757-5b96-4e18-bb21-996afe488148\", \"arguments\": null, \"param_--batch_size\": 64, \"param_--dropout\": 0.8, \"param_--epochs\": 5, \"param_--hidden\": 100}, {\"run_id\": \"HD_72710757-5b96-4e18-bb21-996afe488148_3\", \"run_number\": 6, \"metric\": null, \"status\": \"Queued\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"\", \"end_time\": \"\", \"created_time\": \"2021-01-21T23:03:19.308355Z\", \"created_time_dt\": \"2021-01-21T23:03:19.308355Z\", \"duration\": \"0:00:05\", \"hyperdrive_id\": \"72710757-5b96-4e18-bb21-996afe488148\", \"arguments\": null, \"param_--batch_size\": 64, \"param_--dropout\": 0.5, \"param_--epochs\": 50, \"param_--hidden\": 300}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-01-21T23:02:45.392065][API][INFO]Experiment created\\r\\n[2021-01-21T23:02:46.252155][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-01-21T23:02:46.549476][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-01-21T23:02:47.5343345Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2021-01-21T23:03:18.2792931Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2021-01-21T23:03:18.2822886Z][SCHEDULER][INFO]Scheduling job, id='HD_72710757-5b96-4e18-bb21-996afe488148_2'\\r\\n[2021-01-21T23:03:18.2800767Z][SCHEDULER][INFO]Scheduling job, id='HD_72710757-5b96-4e18-bb21-996afe488148_0'\\r\\n[2021-01-21T23:03:18.2811652Z][SCHEDULER][INFO]Scheduling job, id='HD_72710757-5b96-4e18-bb21-996afe488148_1'\\r\\n[2021-01-21T23:03:18.2834448Z][SCHEDULER][INFO]Scheduling job, id='HD_72710757-5b96-4e18-bb21-996afe488148_3'\\r\\n[2021-01-21T23:03:18.9840658Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72710757-5b96-4e18-bb21-996afe488148_1'\\r\\n[2021-01-21T23:03:19.1379865Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72710757-5b96-4e18-bb21-996afe488148_0'\\r\\n[2021-01-21T23:03:19.5983499Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72710757-5b96-4e18-bb21-996afe488148_3'\\r\\n[2021-01-21T23:03:19.7051767Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_72710757-5b96-4e18-bb21-996afe488148_2'\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.19.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_72710757-5b96-4e18-bb21-996afe488148\n",
            "Web View: https://ml.azure.com/experiments/Sign-Language-HyperDrive/runs/HD_72710757-5b96-4e18-bb21-996afe488148?wsid=/subscriptions/610d6e37-4747-4a20-80eb-3aad70a55f43/resourcegroups/aml-quickstarts-135645/workspaces/quick-starts-ws-135645\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-01-21T23:02:45.392065][API][INFO]Experiment created<END>\\n\"\"<START>[2021-01-21T23:02:46.252155][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-01-21T23:02:46.549476][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2021-01-21T23:02:47.5343345Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\n"
          ]
        }
      ],
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1611269128716
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "assert(hyperdrive_run.get_status() == \"Completed\")\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "print(best_run.get_details()['runDefinition']['arguments'])\n",
        "print(best_run.get_file_names())\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "print('Best accuracy: {}'.format(best_run_metrics['Accuracy']))\n",
        "print(os.listdir('./outputs'))\n",
        "print('========================')"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'ScriptRun' object has no attribute 'get_best_run_by_primary_metric'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-62cd97b9ab91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperdrive_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperdrive_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_run_by_primary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'runDefinition'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arguments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_run_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'ScriptRun' object has no attribute 'get_best_run_by_primary_metric'"
          ]
        }
      ],
      "execution_count": 32,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model = best_run.register_model(model_name='mnist_model.hdf5', model_path='./outputs/mnist_model.hdf5')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run_metrics"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Performance\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.argmax(y_pred, axis =1)\n",
        "y_test = np.argmax(y_test, axis =1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "plt.title('Confusion matrix of the classifier')\n",
        "fig.colorbar(cax)\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.show()\n",
        "print(\"Accuracy :\" + str(round(accuracy_score(y_test, y_pred),4)))\n",
        "p, r, f, s = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
        "print(\"precision: \" + round(p,4))\n",
        "print(\"Recall: \"+round(r,4))\n",
        "print(\"F1: \"+round(f,4))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service.\n",
        "\n",
        "Deploy your model as a web service using Model.deploy(). Web services take one or more models, load them in an environment, and run them on one of several supported deployment targets.  For this example, we will deploy your scikit-learn model to an Azure Container Instance (ACI)."
      ],
      "metadata": {
        "gather": {
          "logged": 1598546650307
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_name = 'sign-language-service'\n",
        "\n",
        "service = Model.deploy(ws, service_name, [model], overwrite=True)\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "\n",
        "input_payload = json.dumps({\n",
        "    'data': dataset_x[0:2].tolist(),\n",
        "    'method': 'predict'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
        "})\n",
        "\n",
        "output = service.run(input_payload)\n",
        "\n",
        "print(output)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service.get_logs()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#cpu_cluster.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.3 64-bit",
      "metadata": {
        "interpreter": {
          "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
        }
      }
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3-final",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}